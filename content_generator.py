"""
Apollo AI Content Generator
G√©n√©ration intelligente de posts, images et vid√©os pour les r√©seaux sociaux
Support OpenAI + Ollama (IA locale gratuite)
"""

from openai import OpenAI
import requests
import random
import json
import os
from datetime import datetime
from PIL import Image, ImageDraw, ImageFont

from config import (
    OPENAI_CONFIG, APOLLO_GYMS, CONTENT_CONFIG, 
    APOLLO_BRAND, POST_TEMPLATES
)

class ApolloContentGenerator:
    def __init__(self):
        # Configuration du provider IA (OpenAI ou Ollama)
        self.ai_provider = os.getenv('AI_PROVIDER', 'ollama')  # Par d√©faut Ollama
        
        if self.ai_provider == 'openai':
            self.client = OpenAI(api_key=OPENAI_CONFIG['api_key'])
            print("ü§ñ Utilisation d'OpenAI GPT")
        else:
            self.ollama_url = os.getenv('OLLAMA_URL', 'http://localhost:11434')
            self.ollama_model = os.getenv('OLLAMA_MODEL', 'llama2:7b-chat')
            print(f"ü¶ô Utilisation d'Ollama - Mod√®le: {self.ollama_model}")
        
        self.brand = APOLLO_BRAND
        self.templates = POST_TEMPLATES
        
    def generate_post_content(self, gym_id, platform, post_type, custom_prompt=None):
        """
        G√©n√®re le contenu d'un post personnalis√© pour une salle Apollo
        """
        gym = self.get_gym_by_id(gym_id)
        platform_config = CONTENT_CONFIG['platforms'][platform]
        
        # Construction du prompt personnalis√©
        prompt = self.build_content_prompt(gym, platform, post_type, custom_prompt)
        
        try:
            # G√©n√©ration selon le provider configur√©
            if self.ai_provider == 'openai':
                content = self._generate_with_openai(prompt)
            else:
                content = self._generate_with_ollama(prompt)
            
            if not content:
                return None
            
            # Post-processing selon la plateforme
            content = self.format_for_platform(content, platform, gym)
            
            return {
                'content': content,
                'gym': gym,
                'platform': platform,
                'type': post_type,
                'generated_at': datetime.now().isoformat(),
                'hashtags': self.generate_hashtags(gym, post_type, platform),
                'optimal_time': self.get_optimal_posting_time(platform),
                'image_suggestion': self.suggest_image_concept(post_type, gym),
                'ai_provider': self.ai_provider
            }
            
        except Exception as e:
            print(f"Erreur g√©n√©ration contenu: {e}")
            return None
    
    def _generate_with_openai(self, prompt):
        """G√©n√©ration avec OpenAI GPT"""
        try:
            response = self.client.chat.completions.create(
                model=OPENAI_CONFIG.get('model', 'gpt-4o-mini'),  # Mod√®le moins cher par d√©faut
                messages=[
                    {"role": "system", "content": self.get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=OPENAI_CONFIG.get('max_tokens', 500),
                temperature=OPENAI_CONFIG.get('temperature', 0.7)
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Erreur OpenAI: {e}")
            return None
    
    def _generate_with_ollama(self, prompt):
        """G√©n√©ration avec Ollama (gratuit, local)"""
        try:
            system_prompt = self.get_system_prompt()
            full_prompt = f"{system_prompt}\n\nUser: {prompt}\n\nAssistant:"
            
            response = requests.post(
                f'{self.ollama_url}/api/generate',
                json={
                    'model': self.ollama_model,
                    'prompt': full_prompt,
                    'stream': False,
                    'options': {
                        'temperature': 0.7,
                        'top_p': 0.9,
                        'max_tokens': 500
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '').strip()
            else:
                print(f"Erreur Ollama: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.ConnectionError:
            print("‚ùå Ollama non disponible. Lancez: ollama serve")
            return None
        except Exception as e:
            print(f"Erreur Ollama: {e}")
            return None
    
    def get_system_prompt(self):
        """Prompt syst√®me pour d√©finir le r√¥le de l'IA"""
        return f"""Tu es le responsable marketing digital d'Apollo Sporting Club, un r√©seau premium de 13 salles de boxe et fitness √† Paris.

IDENTIT√â DE MARQUE:
- Couleurs: Rouge passion #{self.brand['colors']['primary'][1:]}, moderne et √©nergique
- Ton: {self.brand['tone']['style']}, {self.brand['tone']['voice']}
- Valeurs: {', '.join(self.brand['values'])}

MISSION:
- Cr√©er du contenu engageant qui convertit les prospects en membres
- Mettre en valeur l'expertise de nos coachs et l'ambiance unique
- G√©n√©rer des leads qualifi√©s pour chaque salle

STYLE:
- Utilise des emojis pertinents (ü•äüí™üî•‚ö°üéØ)
- Sois inspirant mais authentique
- Inclus toujours un call-to-action clair
- Adapte le ton selon la plateforme (professionnel sur LinkedIn, fun sur TikTok)

R√©ponds UNIQUEMENT avec le contenu du post demand√©."""
    
    def build_content_prompt(self, gym, platform, post_type, custom_prompt):
        """Construit le prompt sp√©cifique pour la g√©n√©ration"""
        base_prompt = f"""Cr√©e un post {post_type} pour Apollo {gym['name']} sur {platform}.

INFOS SALLE:
- Adresse: {gym['address']}
- Sp√©cialit√©s: {', '.join(gym['specialties'])}
- Coachs: {', '.join(gym['coaches'])}
- T√©l√©phone: {gym['phone']}

CONTRAINTES PLATEFORME:
- Max {CONTENT_CONFIG['platforms'][platform]['max_char']} caract√®res
- {CONTENT_CONFIG['platforms'][platform]['optimal_hashtags']} hashtags max

TYPE DE POST: {post_type}"""
        
        if custom_prompt:
            base_prompt += f"\n\nDEMANDE SP√âCIALE: {custom_prompt}"
            
        # Ajout de contexte selon le type de post
        context_prompts = {
            'motivation': "Cr√©e un message motivant pour commencer la semaine, avec une citation inspirante.",
            'workout_tips': "Partage un conseil technique pr√©cis d'un de nos coachs, avec explication claire.",
            'coach_spotlight': f"Met en avant un coach ({random.choice(gym['coaches'])}) avec son expertise.",
            'member_success': "Raconte une success story fictive mais r√©aliste d'un membre Apollo.",
            'nutrition': "Donne un conseil nutrition simple et actionnable pour les sportifs.",
            'boxing_techniques': "Explique une technique de boxe sp√©cifique avec les √©tapes cl√©s.",
            'gym_atmosphere': "D√©cris l'ambiance unique et l'√©nergie de la salle Apollo.",
            'class_schedule': "Pr√©sente les cours de la semaine de fa√ßon engageante.",
            'special_offers': "Annonce une offre sp√©ciale de mani√®re attractive mais non agressive."
        }
        
        if post_type in context_prompts:
            base_prompt += f"\n\nCONTEXTE: {context_prompts[post_type]}"
        
        return base_prompt
    
    def format_for_platform(self, content, platform, gym):
        """Adapte le contenu selon les sp√©cificit√©s de la plateforme"""
        max_chars = CONTENT_CONFIG['platforms'][platform]['max_char']
        
        if len(content) > max_chars:
            content = content[:max_chars-3] + "..."
        
        if platform == 'instagram':
            content += f"\n\nüìç {gym['address']}"
            content += f"\nüìû {gym['phone']}"
            
        elif platform == 'facebook':
            content += f"\n\nPlus d'infos : apollosportingclub.com"
            content += f"\n‚òéÔ∏è R√©servations : {gym['phone']}"
            
        elif platform == 'linkedin':
            content += f"\n\n#Apollo #BoxingFitness #Paris"
            
        return content
    
    def generate_hashtags(self, gym, post_type, platform):
        """G√©n√®re des hashtags optimis√©s pour chaque plateforme"""
        base_hashtags = gym['hashtags'].copy()
        apollo_tags = [
            "#ApolloSportingClub", "#BoxingFitness", 
            "#ParisSport", "#FitnessMotivation", "#BoxingTraining"
        ]
        type_hashtags = {
            'motivation': ["#Motivation", "#FitnessGoals", "#MondayMotivation"],
            'workout_tips': ["#WorkoutTips", "#FitnessTips", "#Training"],
            'coach_spotlight': ["#Coach", "#Expert", "#PersonalTrainer"],
            'boxing_techniques': ["#Boxing", "#BoxingTechnique", "#MartialArts"],
            'nutrition': ["#Nutrition", "#HealthyEating", "#FitnessNutrition"]
        }
        
        all_hashtags = base_hashtags + apollo_tags
        if post_type in type_hashtags:
            all_hashtags.extend(type_hashtags[post_type])
        
        max_hashtags = CONTENT_CONFIG['platforms'][platform]['optimal_hashtags']
        return all_hashtags[:max_hashtags]
    
    def get_optimal_posting_time(self, platform):
        """Retourne l'heure optimale pour publier sur la plateforme"""
        best_times = CONTENT_CONFIG['platforms'][platform]['best_times']
        return random.choice(best_times)
    
    def suggest_image_concept(self, post_type, gym):
        """Sugg√®re un concept d'image pour accompagner le post"""
        concepts = {
            'motivation': f"Athl√®te en action dans la salle Apollo {gym['name']}, √©clairage dramatique rouge",
            'workout_tips': f"Coach {random.choice(gym['coaches'])} d√©montrant l'exercice",
            'coach_spotlight': f"Portrait professionnel du coach avec √©quipements Apollo",
            'boxing_techniques': "S√©quence de mouvement de boxe en 3 √©tapes, style tutorial",
            'gym_atmosphere': f"Vue d'ensemble de la salle Apollo {gym['name']} avec membres en activit√©"
        }
        return concepts.get(post_type, "Visuel Apollo avec logo et couleurs de marque")
    
    def generate_image_with_dalle(self, concept, style="modern fitness photography"):
        """G√©n√®re une image avec DALL-E bas√©e sur le concept (OpenAI seulement)"""
        if self.ai_provider != 'openai':
            print("‚ö†Ô∏è G√©n√©ration d'images disponible uniquement avec OpenAI")
            return None
            
        try:
            prompt = f"{concept}, {style}, high quality, professional, Apollo red and black colors"
            response = self.client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size="1024x1024",
                quality="standard",
                n=1
            )
            return response.data[0].url
        except Exception as e:
            print(f"Erreur g√©n√©ration image: {e}")
            return None
    
    def create_branded_image(self, text, background_color=None):
        """Cr√©e une image de marque avec texte overlay"""
        if not background_color:
            background_color = self.brand['colors']['primary']
            
        width, height = 1080, 1080
        img = Image.new('RGB', (width, height), background_color)
        draw = ImageDraw.Draw(img)
        
        try:
            font = ImageFont.truetype("arial.ttf", 60)
        except:
            font = ImageFont.load_default()
        
        text_bbox = draw.textbbox((0, 0), text, font=font)
        text_width = text_bbox[2] - text_bbox[0]
        text_height = text_bbox[3] - text_bbox[1]
        
        x = (width - text_width) // 2
        y = (height - text_height) // 2
        draw.text((x, y), text, fill='white', font=font)
        
        img_path = f"temp_image_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        img.save(img_path)
        return img_path
    
    def generate_batch_content(self, gym_ids=None, platforms=None, count=10):
        """G√©n√®re un lot de contenus pour plusieurs salles/plateformes"""
        if not gym_ids:
            gym_ids = [gym['id'] for gym in APOLLO_GYMS]
        if not platforms:
            platforms = list(CONTENT_CONFIG['platforms'].keys())
        
        generated_content = []
        post_types = CONTENT_CONFIG['post_types']
        
        for _ in range(count):
            gym_id = random.choice(gym_ids)
            platform = random.choice(platforms)
            post_type = random.choice(post_types)
            
            content = self.generate_post_content(gym_id, platform, post_type)
            if content:
                generated_content.append(content)
        
        return generated_content
    
    def get_gym_by_id(self, gym_id):
        """R√©cup√®re les donn√©es d'une salle par son ID"""
        for gym in APOLLO_GYMS:
            if gym['id'] == gym_id:
                return gym
        return APOLLO_GYMS[0]
    
    def save_content_batch(self, content_batch, filename=None):
        """Sauvegarde un lot de contenus g√©n√©r√©s"""
        if not filename:
            filename = f"apollo_content_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        os.makedirs('data/generated_content', exist_ok=True)
        filepath = f"data/generated_content/{filename}"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(content_batch, f, indent=2, ensure_ascii=False)
        
        return filepath

# =============================================================================
# FONCTIONS D'INSTALLATION ET TEST OLLAMA
# =============================================================================

def check_ollama_status():
    """V√©rifie si Ollama est disponible et install√©"""
    try:
        response = requests.get('http://localhost:11434/api/tags', timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"‚úÖ Ollama disponible avec {len(models)} mod√®les")
            for model in models:
                print(f"   - {model['name']}")
            return True
        else:
            print("‚ùå Ollama non disponible")
            return False
    except:
        print("‚ùå Ollama non install√© ou non lanc√©")
        return False

def install_ollama_model(model_name="llama2:7b-chat"):
    """Installe un mod√®le Ollama"""
    print(f"üì• Installation du mod√®le {model_name}...")
    print("(Cela peut prendre plusieurs minutes)")
    
    try:
        response = requests.post(
            'http://localhost:11434/api/pull',
            json={'name': model_name},
            stream=True,
            timeout=600
        )
        
        for line in response.iter_lines():
            if line:
                data = json.loads(line)
                if 'status' in data:
                    print(f"üìä {data['status']}")
        
        print(f"‚úÖ Mod√®le {model_name} install√© avec succ√®s!")
        return True
    except Exception as e:
        print(f"‚ùå Erreur installation: {e}")
        return False

# =============================================================================
# FONCTION DE DEMO
# =============================================================================

def demo_content_generation():
    print("üöÄ Apollo AI Content Generator - D√âMO AM√âLIOR√âE")
    print("=" * 60)
    
    # V√©rification des providers disponibles
    print("\nüîç V√âRIFICATION DES PROVIDERS IA:")
    
    ai_provider = os.getenv('AI_PROVIDER', 'ollama')
    print(f"üéØ Provider configur√©: {ai_provider}")
    
    if ai_provider == 'ollama':
        if not check_ollama_status():
            print("\n‚ùå Ollama non disponible.")
            print("üìã INSTRUCTIONS D'INSTALLATION:")
            print("1. Installer: brew install ollama")
            print("2. Lancer: ollama serve")
            print("3. Installer mod√®le: ollama pull llama2:7b-chat")
            print("4. Relancer cette d√©mo")
            return
    
    generator = ApolloContentGenerator()
    
    print(f"\nüìù Test g√©n√©ration d'un post motivation pour Apollo Bastille sur Instagram:")
    content = generator.generate_post_content(
        gym_id=1, 
        platform='instagram', 
        post_type='motivation'
    )
    
    if content:
        print(f"\n‚úÖ CONTENU G√âN√âR√â AVEC {content['ai_provider'].upper()}:")
        print(f"üì± Plateforme: {content['platform']}")
        print(f"üèãÔ∏è Salle: {content['gym']['name']}")
        print(f"üéØ Type: {content['type']}")
        print(f"‚è∞ Heure optimale: {content['optimal_time']}")
        print(f"\nüìù CONTENU:\n{content['content']}")
        print(f"\nüè∑Ô∏è HASHTAGS:\n{' '.join(content['hashtags'])}")
        print(f"\nüñºÔ∏è SUGGESTION IMAGE:\n{content['image_suggestion']}")
    
    print(f"\n\nüì¶ Test g√©n√©ration de 3 posts vari√©s:")
    batch = generator.generate_batch_content(count=3)
    for i, item in enumerate(batch, 1):
        print(f"\n{i}. {item['gym']['name']} - {item['platform']} - {item['type']}")
    
    if batch:
        filepath = generator.save_content_batch(batch, "demo_batch_ollama.json")
        print(f"\nüíæ Contenu sauvegard√© dans: {filepath}")
    
    print(f"\nüéâ D√©mo termin√©e! {len(batch)} contenus g√©n√©r√©s avec succ√®s.")
    print(f"ü§ñ Provider utilis√©: {generator.ai_provider}")

if __name__ == "__main__":
    demo_content_generation()